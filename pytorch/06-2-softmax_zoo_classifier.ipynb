{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOQstC6N/okLC7uvPj6AV2x"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eCStxQGLkdE8","executionInfo":{"status":"ok","timestamp":1672098772092,"user_tz":-540,"elapsed":1166,"user":{"displayName":"신명근","userId":"14329502532076519745"}},"outputId":"9d57c8f8-22e4-4136-f8df-21df3b9b0b82"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fbece94d050>"]},"metadata":{},"execution_count":1}],"source":["import torch\n","from torch.autograd import Variable\n","import numpy as np\n","\n","torch.manual_seed(777) # for reproducibility"]},{"cell_type":"code","source":["# Predicting animal type based on various features\n","xy = np.loadtxt('data-04-zoo.csv', delimiter = ',', dtype = np.float32)\n","x_data = xy[:, 0:-1]\n","y_data = xy[:, [-1]]"],"metadata":{"id":"YejOoffXkpQA","executionInfo":{"status":"ok","timestamp":1672098772092,"user_tz":-540,"elapsed":4,"user":{"displayName":"신명근","userId":"14329502532076519745"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["print(x_data.shape, y_data.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9I2lfVAfk4ee","executionInfo":{"status":"ok","timestamp":1672098772092,"user_tz":-540,"elapsed":4,"user":{"displayName":"신명근","userId":"14329502532076519745"}},"outputId":"363ce784-217e-49ac-e67a-43f53c78cbab"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["(101, 16) (101, 1)\n"]}]},{"cell_type":"code","source":["nb_classes = 7 # 0 ~ 6"],"metadata":{"id":"RX33faNCk7k1","executionInfo":{"status":"ok","timestamp":1672098772092,"user_tz":-540,"elapsed":2,"user":{"displayName":"신명근","userId":"14329502532076519745"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["X = Variable(torch.from_numpy(x_data))\n","Y = Variable(torch.from_numpy(y_data))"],"metadata":{"id":"eEDsgR59k-LN","executionInfo":{"status":"ok","timestamp":1672098772092,"user_tz":-540,"elapsed":2,"user":{"displayName":"신명근","userId":"14329502532076519745"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# one hot encoding\n","Y_one_hot = torch.zeros(Y.size()[0], nb_classes)\n","Y_one_hot.scatter_(1, Y.long().data, 1)\n","Y_one_hot = Variable(Y_one_hot)\n","print(\"one_hot\", Y_one_hot.data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1rzXnHFllEwN","executionInfo":{"status":"ok","timestamp":1672098773820,"user_tz":-540,"elapsed":3,"user":{"displayName":"신명근","userId":"14329502532076519745"}},"outputId":"263790e0-51fb-4b09-8e2e-2911b9b4f12d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["one_hot tensor([[1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1.],\n","        [0., 0., 0., 0., 0., 0., 1.],\n","        [0., 0., 0., 0., 0., 0., 1.],\n","        [0., 1., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0.],\n","        [0., 0., 0., 0., 1., 0., 0.],\n","        [0., 0., 0., 0., 1., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0.],\n","        [0., 0., 0., 0., 0., 1., 0.],\n","        [0., 1., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0.],\n","        [0., 1., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0.],\n","        [0., 0., 0., 0., 1., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0.],\n","        [0., 0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1.],\n","        [0., 0., 0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 1., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1.],\n","        [0., 1., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0.],\n","        [0., 0., 1., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1.],\n","        [0., 0., 0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1.],\n","        [0., 0., 0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0.],\n","        [0., 0., 0., 0., 1., 0., 0.],\n","        [0., 0., 1., 0., 0., 0., 0.],\n","        [0., 0., 1., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0.],\n","        [1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1.],\n","        [0., 1., 0., 0., 0., 0., 0.]])\n"]}]},{"cell_type":"code","source":["softmax = torch.nn.Softmax()\n","model = torch.nn.Linear(16, nb_classes, bias = True)"],"metadata":{"id":"JvUehBd4lawp","executionInfo":{"status":"ok","timestamp":1672098775654,"user_tz":-540,"elapsed":2,"user":{"displayName":"신명근","userId":"14329502532076519745"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Cross entropy cost/loss\n","criterion = torch.nn.CrossEntropyLoss() # Softmax is internally computed.\n","optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)"],"metadata":{"id":"WyHwGk3WljqB","executionInfo":{"status":"ok","timestamp":1672098776119,"user_tz":-540,"elapsed":1,"user":{"displayName":"신명근","userId":"14329502532076519745"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["for step in range(2001):\n","  optimizer.zero_grad()\n","  hypothesis = model(X)\n","  # Label has to be 1D LongTensor\n","  cost = criterion(hypothesis, Y.long().view(-1))\n","  cost.backward()\n","  optimizer.step()\n","\n","  prediction = torch.max(softmax(hypothesis), 1)[1].float()\n","\n","  correct_prediction = (prediction.data == Y.data)\n","  accuracy = correct_prediction.float().mean()\n","\n","  if step % 100 == 0:\n","    print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(step, cost.data, accuracy))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1-WVZYqOltR4","executionInfo":{"status":"ok","timestamp":1672098779298,"user_tz":-540,"elapsed":2422,"user":{"displayName":"신명근","userId":"14329502532076519745"}},"outputId":"9c62dc24-fe2d-48b9-f081-9b498f545a8a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-9-a1a8de49f5db>:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  prediction = torch.max(softmax(hypothesis), 1)[1].float()\n"]},{"output_type":"stream","name":"stdout","text":["Step:     0\tLoss: 2.446\tAcc: 9.79%\n","Step:   100\tLoss: 0.488\tAcc: 25.88%\n","Step:   200\tLoss: 0.333\tAcc: 24.93%\n","Step:   300\tLoss: 0.257\tAcc: 24.47%\n","Step:   400\tLoss: 0.211\tAcc: 24.47%\n","Step:   500\tLoss: 0.179\tAcc: 24.27%\n","Step:   600\tLoss: 0.156\tAcc: 24.19%\n","Step:   700\tLoss: 0.138\tAcc: 24.21%\n","Step:   800\tLoss: 0.124\tAcc: 24.21%\n","Step:   900\tLoss: 0.113\tAcc: 24.07%\n","Step:  1000\tLoss: 0.103\tAcc: 24.07%\n","Step:  1100\tLoss: 0.095\tAcc: 24.07%\n","Step:  1200\tLoss: 0.088\tAcc: 24.07%\n","Step:  1300\tLoss: 0.082\tAcc: 24.07%\n","Step:  1400\tLoss: 0.077\tAcc: 24.07%\n","Step:  1500\tLoss: 0.073\tAcc: 24.07%\n","Step:  1600\tLoss: 0.069\tAcc: 24.07%\n","Step:  1700\tLoss: 0.065\tAcc: 24.07%\n","Step:  1800\tLoss: 0.062\tAcc: 24.07%\n","Step:  1900\tLoss: 0.059\tAcc: 24.07%\n","Step:  2000\tLoss: 0.056\tAcc: 24.07%\n"]}]}]}